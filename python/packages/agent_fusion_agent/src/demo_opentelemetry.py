"""OpenTelemetryæ¼”ç¤ºæ–‡ä»¶

è¿è¡Œå„ç§OpenTelemetryç¤ºä¾‹ï¼Œå±•ç¤ºè¿½è¸ªå’Œç›‘æ§åŠŸèƒ½ã€‚
"""

import asyncio
import time
from typing import Dict, Any

from .opentelemetry_config import setup_opentelemetry, cleanup_opentelemetry
from .opentelemetry_integration import TracedAgent, OpenTelemetryObservabilityManager


class OpenTelemetryDemo:
    """OpenTelemetryæ¼”ç¤ºç±»"""
    
    def __init__(self):
        self.setup_complete = False
    
    def setup(self):
        """è®¾ç½®OpenTelemetry"""
        print("ğŸ”§ Setting up OpenTelemetry...")
        setup_opentelemetry(
            service_name="agent-fusion-demo",
            service_version="1.0.0",
            console_export=True  # è¾“å‡ºåˆ°æ§åˆ¶å°ä¾¿äºè§‚å¯Ÿ
        )
        self.setup_complete = True
        print("âœ… OpenTelemetry setup complete!")
    
    def demo_basic_agent_interaction(self):
        """æ¼”ç¤ºåŸºæœ¬Agentäº¤äº’"""
        print("\nğŸ¤– Demo: Basic Agent Interaction")
        print("=" * 50)
        
        # åˆ›å»ºå¸¦è¿½è¸ªçš„Agent
        agent = TracedAgent("demo_agent", "gpt-4")
        
        # å¤„ç†å‡ ä¸ªä¸åŒçš„æ¶ˆæ¯
        messages = [
            "Hello, how are you?",
            "What's the weather like today?",
            "Can you help me with Python programming?",
            "Tell me a joke"
        ]
        
        for i, message in enumerate(messages):
            print(f"\nğŸ’¬ Processing message {i+1}: {message}")
            
            result = agent.process_message(
                user_id=f"user_{i+1}",
                message=message,
                context={
                    "session_id": f"session_{i+1}",
                    "channel": "demo",
                    "timestamp": time.time()
                }
            )
            
            print(f"âœ… Response: {result['response']}")
            print(f"ğŸ“Š Status: {result['status']}")
            
            # ç¨å¾®ç­‰å¾…ä¸€ä¸‹ï¼Œä¾¿äºè§‚å¯Ÿ
            time.sleep(0.1)
        
        # è·å–æŒ‡æ ‡æ‘˜è¦
        metrics = agent.observability.get_metrics_summary()
        print(f"\nğŸ“ˆ Metrics Summary:")
        print(f"   Total interactions: {metrics.get('total_interactions', 0)}")
        print(f"   Successful interactions: {metrics.get('successful_interactions', 0)}")
        print(f"   Success rate: {metrics.get('success_rate', 0):.2%}")
        print(f"   Average duration: {metrics.get('average_duration_ms', 0):.2f}ms")
    
    def demo_error_handling(self):
        """æ¼”ç¤ºé”™è¯¯å¤„ç†"""
        print("\nğŸš¨ Demo: Error Handling")
        print("=" * 50)
        
        agent = TracedAgent("error_demo_agent", "gpt-4")
        
        # æ¨¡æ‹Ÿä¸€ä¸ªä¼šäº§ç”Ÿé”™è¯¯çš„åœºæ™¯
        class ErrorAgent(TracedAgent):
            def _generate_response(self, interaction_id: str, user_id: str, message: str) -> str:
                # æ¨¡æ‹Ÿç‰¹å®šæ¡ä»¶ä¸‹çš„é”™è¯¯
                if "error" in message.lower():
                    raise ValueError("Simulated error for demonstration")
                return super()._generate_response(interaction_id, user_id, message)
        
        error_agent = ErrorAgent("error_agent", "gpt-4")
        
        # æ­£å¸¸æ¶ˆæ¯
        print("\nâœ… Processing normal message...")
        result = error_agent.process_message("user_1", "Hello there!")
        print(f"Response: {result['response']}")
        
        # è§¦å‘é”™è¯¯çš„æ¶ˆæ¯
        print("\nâŒ Processing message that will trigger error...")
        result = error_agent.process_message("user_2", "This will cause an error")
        print(f"Response: {result['response']}")
        print(f"Error: {result.get('error', 'No error')}")
        
        # æ£€æŸ¥æŒ‡æ ‡
        metrics = error_agent.observability.get_metrics_summary()
        print(f"\nğŸ“Š Error Handling Metrics:")
        print(f"   Total interactions: {metrics.get('total_interactions', 0)}")
        print(f"   Failed interactions: {metrics.get('failed_interactions', 0)}")
        print(f"   Success rate: {metrics.get('success_rate', 0):.2%}")
    
    def demo_distributed_tracing(self):
        """æ¼”ç¤ºåˆ†å¸ƒå¼è¿½è¸ª"""
        print("\nğŸŒ Demo: Distributed Tracing")
        print("=" * 50)
        
        # æ¨¡æ‹Ÿä¸¤ä¸ªä¸åŒçš„æœåŠ¡
        service_a_agent = TracedAgent("service_a_agent", "gpt-4")
        service_b_agent = TracedAgent("service_b_agent", "gpt-3.5-turbo")
        
        # æœåŠ¡Aå¤„ç†æ¶ˆæ¯
        print("\nğŸ”µ Service A processing message...")
        result_a = service_a_agent.process_message(
            "user_distributed",
            "This is a distributed request",
            {"service": "A", "step": 1}
        )
        
        # è·å–è¿½è¸ªä¸Šä¸‹æ–‡
        trace_context = service_a_agent.get_trace_context(result_a["interaction_id"])
        print(f"ğŸ“‹ Trace context headers: {list(trace_context.keys())}")
        
        # æœåŠ¡Bç»§ç»­å¤„ç†ï¼ˆæ¨¡æ‹Ÿæ¥æ”¶åˆ°åˆ†å¸ƒå¼è°ƒç”¨ï¼‰
        print("\nğŸŸ¢ Service B continuing the trace...")
        
        # åˆ›å»ºæ–°çš„å¯è§‚æµ‹æ€§ç®¡ç†å™¨å¹¶ç»§ç»­è¿½è¸ª
        service_b_observability = OpenTelemetryObservabilityManager()
        interaction_id_b = service_b_observability.start_interaction(
            context={"service": "B", "step": 2, "parent_service": "A"}
        )
        
        # ç»§ç»­åˆ†å¸ƒå¼è¿½è¸ª
        service_b_observability.continue_trace(interaction_id_b, trace_context)
        
        # æ¨¡æ‹Ÿä¸€äº›å¤„ç†
        service_b_observability.add_span_event(
            interaction_id_b,
            "distributed_processing_started",
            {"received_from": "service_a"}
        )
        
        time.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        service_b_observability.add_span_event(
            interaction_id_b,
            "distributed_processing_completed",
            {"processing_time": 0.2}
        )
        
        # ç»“æŸåˆ†å¸ƒå¼è¿½è¸ª
        service_b_observability.end_interaction(interaction_id_b)
        
        print("âœ… Distributed tracing completed!")
    
    def demo_concurrent_interactions(self):
        """æ¼”ç¤ºå¹¶å‘äº¤äº’"""
        print("\nâš¡ Demo: Concurrent Interactions")
        print("=" * 50)
        
        agent = TracedAgent("concurrent_agent", "gpt-4")
        
        # å¹¶å‘å¤„ç†å¤šä¸ªæ¶ˆæ¯
        async def process_concurrent_messages():
            tasks = []
            messages = [
                ("user_1", "What's 2+2?"),
                ("user_2", "Tell me about Python"),
                ("user_3", "How's the weather?"),
                ("user_4", "What's your favorite color?"),
                ("user_5", "Can you help me?")
            ]
            
            for user_id, message in messages:
                # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡ï¼ˆè™½ç„¶process_messageæ˜¯åŒæ­¥çš„ï¼Œä½†æˆ‘ä»¬å¯ä»¥ç”¨çº¿ç¨‹æ± ï¼‰
                task = asyncio.create_task(
                    asyncio.to_thread(
                        agent.process_message,
                        user_id,
                        message,
                        {"concurrent": True, "timestamp": time.time()}
                    )
                )
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks)
            return results
        
        # è¿è¡Œå¹¶å‘å¤„ç†
        print("ğŸš€ Starting concurrent processing...")
        start_time = time.time()
        
        results = asyncio.run(process_concurrent_messages())
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"âœ… Processed {len(results)} messages concurrently in {total_time:.2f}s")
        
        # æ˜¾ç¤ºç»“æœ
        for i, result in enumerate(results):
            print(f"   Message {i+1}: {result['status']}")
        
        # è·å–æŒ‡æ ‡
        metrics = agent.observability.get_metrics_summary()
        print(f"\nğŸ“Š Concurrent Processing Metrics:")
        print(f"   Total interactions: {metrics.get('total_interactions', 0)}")
        print(f"   Average duration: {metrics.get('average_duration_ms', 0):.2f}ms")
        print(f"   Success rate: {metrics.get('success_rate', 0):.2%}")
    
    def demo_custom_spans_and_events(self):
        """æ¼”ç¤ºè‡ªå®šä¹‰Spanså’ŒEvents"""
        print("\nğŸ¯ Demo: Custom Spans and Events")
        print("=" * 50)
        
        agent = TracedAgent("custom_agent", "gpt-4")
        
        # å¼€å§‹ä¸€ä¸ªäº¤äº’
        interaction_id = agent.observability.start_interaction(
            context={"demo": "custom_spans", "user_type": "premium"}
        )
        
        try:
            # æ·»åŠ è‡ªå®šä¹‰äº‹ä»¶
            agent.observability.add_span_event(
                interaction_id,
                "user_authentication_started",
                {"auth_method": "oauth2"}
            )
            
            time.sleep(0.05)  # æ¨¡æ‹Ÿè®¤è¯æ—¶é—´
            
            agent.observability.add_span_event(
                interaction_id,
                "user_authentication_completed",
                {"auth_result": "success", "user_role": "premium"}
            )
            
            # è®¾ç½®è‡ªå®šä¹‰å±æ€§
            agent.observability.set_span_attribute(
                interaction_id,
                "user.premium_status",
                True
            )
            
            agent.observability.set_span_attribute(
                interaction_id,
                "feature.advanced_processing",
                True
            )
            
            # æ¨¡æ‹Ÿå¤æ‚çš„å¤„ç†æµç¨‹
            for step in range(3):
                agent.observability.add_span_event(
                    interaction_id,
                    f"processing_step_{step + 1}",
                    {"step": step + 1, "complexity": "high"}
                )
                time.sleep(0.02)
            
            # æœ€ç»ˆäº‹ä»¶
            agent.observability.add_span_event(
                interaction_id,
                "custom_processing_completed",
                {"total_steps": 3, "result": "success"}
            )
            
            print("âœ… Custom spans and events added successfully!")
            
        finally:
            # ç»“æŸäº¤äº’
            agent.observability.end_interaction(interaction_id)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\nğŸ§¹ Cleaning up OpenTelemetry resources...")
        cleanup_opentelemetry()
        print("âœ… Cleanup complete!")
    
    def run_all_demos(self):
        """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
        if not self.setup_complete:
            self.setup()
        
        print("\nğŸ¬ Starting OpenTelemetry Demos")
        print("=" * 60)
        
        try:
            # è¿è¡Œå„ç§æ¼”ç¤º
            self.demo_basic_agent_interaction()
            self.demo_error_handling()
            self.demo_distributed_tracing()
            self.demo_concurrent_interactions()
            self.demo_custom_spans_and_events()
            
            print("\nğŸ‰ All demos completed successfully!")
            
        except Exception as e:
            print(f"\nâŒ Demo failed with error: {e}")
            raise
        finally:
            self.cleanup()


def main():
    """ä¸»å‡½æ•°"""
    demo = OpenTelemetryDemo()
    demo.run_all_demos()


if __name__ == "__main__":
    main() 