# AutoGen AssistantAgent å®Œæ•´æµç¨‹è§£æ

åŸºäº `autogen_agentchat.agents._assistant_agent.py` æºç çš„è¯¦ç»†åˆ†æ

## æ•´ä½“æ¶æ„æ¦‚è§ˆ

AssistantAgent çš„ `on_messages_stream` æ–¹æ³•æ˜¯ä¸€ä¸ªå¤æ‚çš„å¤šé˜¶æ®µå¤„ç†æµç¨‹ï¼Œæ”¯æŒï¼š
- æµå¼å“åº”
- å·¥å…·è°ƒç”¨å¾ªç¯
- å†…å­˜é›†æˆ
- åæ€æœºåˆ¶
- ç»“æ„åŒ–è¾“å‡º

## è¯¦ç»†æµç¨‹è§£æ

### ğŸš€ **ä¸»å…¥å£ï¼šon_messages_stream() (è¡Œ 901-1010)**

#### **é˜¶æ®µ1ï¼šçŠ¶æ€æ”¶é›†å’Œåˆå§‹åŒ– (è¡Œ 916-931)**
```python
# æ”¶é›†æ‰€æœ‰ç›¸å…³çŠ¶æ€
agent_name = self.name
model_context = self._model_context
memory = self._memory
system_messages = self._system_messages
workbench = self._workbench
handoff_tools = self._handoff_tools
# ... ç­‰ç­‰
```

#### **é˜¶æ®µ2ï¼šæ¶ˆæ¯ä¸Šä¸‹æ–‡ç®¡ç† (è¡Œ 932-946)**
```python
# STEP 1: å°†æ–°çš„ç”¨æˆ·/ç§»äº¤æ¶ˆæ¯æ·»åŠ åˆ°æ¨¡å‹ä¸Šä¸‹æ–‡
await self._add_messages_to_context(
    model_context=model_context,
    messages=messages,
)

# STEP 2: ä½¿ç”¨ç›¸å…³å†…å­˜æ›´æ–°æ¨¡å‹ä¸Šä¸‹æ–‡
for event_msg in await self._update_model_context_with_memory(...):
    inner_messages.append(event_msg)
    yield event_msg
```

#### **é˜¶æ®µ3ï¼šç¬¬ä¸€æ¬¡LLMæ¨ç† (è¡Œ 948-986)**
```python
# STEP 4: è¿è¡Œç¬¬ä¸€æ¬¡æ¨ç†
async for inference_output in self._call_llm(...):
    if isinstance(inference_output, CreateResult):
        model_result = inference_output
    else:
        # æµå¼å—äº‹ä»¶
        yield inference_output

# å¤„ç†éšè—çš„"æ€è€ƒ"å†…å®¹
if model_result.thought:
    thought_event = ThoughtEvent(content=model_result.thought, source=agent_name)
    yield thought_event

# å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°æ¨¡å‹ä¸Šä¸‹æ–‡
await model_context.add_message(AssistantMessage(...))
```

#### **é˜¶æ®µ4ï¼šæ¨¡å‹ç»“æœå¤„ç† (è¡Œ 988-1009)**
```python
# STEP 5: å¤„ç†æ¨¡å‹è¾“å‡º
async for output_event in self._process_model_result(...):
    yield output_event
```

---

### ğŸ”§ **æ ¸å¿ƒæ–¹æ³•1ï¼š_call_llm() (è¡Œ 1053-1114)**

**èŒè´£**ï¼šæ‰§è¡Œå®é™…çš„LLMæ¨ç†è°ƒç”¨

#### **å…³é”®æ­¥éª¤ï¼š**

1. **ä¸Šä¸‹æ–‡å‡†å¤‡ (è¡Œ 1083-1086)**ï¼š
   ```python
   all_messages = await model_context.get_messages()
   llm_messages = cls._get_compatible_context(model_client=model_client, messages=system_messages + all_messages)
   tools = [tool for wb in workbench for tool in await wb.list_tools()] + handoff_tools
   ```

2. **æµå¼ vs éæµå¼å¤„ç† (è¡Œ 1088-1113)**ï¼š
   ```python
   if model_client_stream:
       async for chunk in model_client.create_stream(...):
           if isinstance(chunk, CreateResult):
               model_result = chunk
           elif isinstance(chunk, str):
               yield ModelClientStreamingChunkEvent(content=chunk, source=agent_name, full_message_id=message_id)
   else:
       model_result = await model_client.create(...)
   ```

**å…³é”®ç‰¹æ€§**ï¼š
- âœ… æ”¯æŒæµå¼å’Œéæµå¼æ¨ç†
- âœ… è‡ªåŠ¨å·¥å…·é›†æˆ
- âœ… æ¶ˆæ¯IDå…³è”ç”¨äºæµå¼å—è¿½è¸ª
- âœ… å…¼å®¹æ€§æ£€æŸ¥ï¼ˆè§†è§‰ç­‰ï¼‰

---

### âš™ï¸ **æ ¸å¿ƒæ–¹æ³•2ï¼š_process_model_result() (è¡Œ 1116-1340+)**

**èŒè´£**ï¼šå¤„ç†LLMè¿”å›çš„ç»“æœï¼Œæ”¯æŒå·¥å…·è°ƒç”¨å¾ªç¯

#### **å·¥å…·è°ƒç”¨å¾ªç¯é€»è¾‘ (è¡Œ 1147-1296)**ï¼š

```python
for loop_iteration in range(max_tool_iterations):
    # æƒ…å†µ1ï¼šçº¯æ–‡æœ¬å“åº” (è¡Œ 1148-1173)
    if isinstance(current_model_result.content, str):
        if output_content_type:
            # ç»“æ„åŒ–è¾“å‡º
            content = output_content_type.model_validate_json(current_model_result.content)
            yield Response(chat_message=StructuredMessage[output_content_type](...))
        else:
            # æ™®é€šæ–‡æœ¬è¾“å‡º
            yield Response(chat_message=TextMessage(...))
        return
    
    # æƒ…å†µ2ï¼šå·¥å…·è°ƒç”¨ (è¡Œ 1175-1296)
    assert isinstance(current_model_result.content, list) and all(
        isinstance(item, FunctionCall) for item in current_model_result.content
    )
    
    # 4A: ç”Ÿæˆå·¥å…·è°ƒç”¨è¯·æ±‚äº‹ä»¶
    tool_call_msg = ToolCallRequestEvent(content=current_model_result.content, ...)
    yield tool_call_msg
    
    # 4B: æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆæ”¯æŒæµå¼ï¼‰
    async def _execute_tool_calls(...):
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        results = await asyncio.gather(*[
            cls._execute_tool_call_with_streaming(...)
            for call in function_calls
        ])
    
    # 4C: å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ
    for call, result in calls_and_results:
        tool_result_msg = ToolCallExecutionEvent(...)
        yield tool_result_msg
        
        # æ£€æŸ¥ç§»äº¤æ“ä½œ
        if call.name in handoffs:
            handoff_msg = cls._create_handoff_message(...)
            yield Response(chat_message=handoff_msg, ...)
            return
    
    # 4D: å°†å·¥å…·ç»“æœæ·»åŠ åˆ°ä¸Šä¸‹æ–‡ï¼Œå‡†å¤‡ä¸‹ä¸€è½®æ¨ç†
    for call, result in calls_and_results:
        await model_context.add_message(ToolResultMessage(...))
    
    # 4E: å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¿›è¡Œä¸‹ä¸€è½®LLMè°ƒç”¨
    if loop_iteration < max_tool_iterations - 1:
        async for inference_output in cls._call_llm(...):
            if isinstance(inference_output, CreateResult):
                current_model_result = inference_output
            else:
                yield inference_output
```

#### **åæ€æˆ–æ€»ç»“é˜¶æ®µ (è¡Œ 1297-1340)**ï¼š

```python
# å¾ªç¯ç»“æŸåï¼Œæ ¹æ®é…ç½®è¿›è¡Œåæ€æˆ–æ€»ç»“
if reflect_on_tool_use:
    # åæ€æµç¨‹ï¼šç¬¬äºŒæ¬¡LLMè°ƒç”¨
    async for reflection_response in cls._reflect_on_tool_use_flow(
        system_messages=system_messages,
        model_client=model_client,
        model_client_stream=model_client_stream,
        model_context=model_context,
        workbench=workbench,
        handoff_tools=handoff_tools,
        agent_name=agent_name,
        inner_messages=inner_messages,
        output_content_type=output_content_type,
        cancellation_token=cancellation_token,
    ):
        yield reflection_response
else:
    # ç›´æ¥æ€»ç»“ï¼šæ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœ
    summary_content = cls._summarize_tool_use(
        executed_calls_and_results,
        tool_call_summary_format,
        tool_call_summary_formatter,
    )
    yield Response(chat_message=ToolCallSummaryMessage(...))
```

---

### ğŸ¤” **åæ€æµç¨‹ï¼š_reflect_on_tool_use_flow() (è¡Œ 1380-1460+)**

**èŒè´£**ï¼šå¯¹å·¥å…·ä½¿ç”¨ç»“æœè¿›è¡ŒLLMåæ€ï¼Œç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Š

#### **å…³é”®ç‰¹æ€§**ï¼š
1. **ç¬¬äºŒæ¬¡LLMè°ƒç”¨**ï¼šä½¿ç”¨åŒ…å«å·¥å…·ç»“æœçš„å®Œæ•´ä¸Šä¸‹æ–‡
2. **ç¦ç”¨å·¥å…·**ï¼š`tool_choice="none"` é˜²æ­¢é€’å½’å·¥å…·è°ƒç”¨
3. **ç»“æ„åŒ–è¾“å‡ºæ”¯æŒ**ï¼šç¡®ä¿è¾“å‡ºç¬¦åˆæŒ‡å®šæ ¼å¼
4. **æµå¼æ”¯æŒ**ï¼šæ”¯æŒæµå¼åæ€å“åº”

```python
async for chunk in model_client.create_stream(
    llm_messages,
    json_output=output_content_type,
    cancellation_token=cancellation_token,
    tool_choice="none",  # å…³é”®ï¼šä¸ä½¿ç”¨å·¥å…·
):
    if isinstance(chunk, CreateResult):
        # å¤„ç†æœ€ç»ˆåæ€ç»“æœ
        reflection_content = chunk.content
        if output_content_type:
            content = output_content_type.model_validate_json(reflection_content)
            yield Response(chat_message=StructuredMessage[output_content_type](...))
        else:
            yield Response(chat_message=TextMessage(...))
    elif isinstance(chunk, str):
        # æµå¼åæ€å—
        yield ModelClientStreamingChunkEvent(...)
```

---

## ğŸ”„ **å®Œæ•´æµç¨‹å›¾**

```mermaid
graph TD
    A[ç”¨æˆ·æ¶ˆæ¯] --> B[æ·»åŠ åˆ°ä¸Šä¸‹æ–‡]
    B --> C[å†…å­˜é›†æˆ]
    C --> D[ç¬¬ä¸€æ¬¡LLMè°ƒç”¨]
    D --> E{å“åº”ç±»å‹?}
    
    E -->|çº¯æ–‡æœ¬| F[ç›´æ¥è¿”å›Response]
    E -->|å·¥å…·è°ƒç”¨| G[ç”ŸæˆToolCallRequestEvent]
    
    G --> H[æ‰§è¡Œå·¥å…·è°ƒç”¨]
    H --> I[ç”ŸæˆToolCallExecutionEvent]
    I --> J{è¾¾åˆ°æœ€å¤§è¿­ä»£?}
    
    J -->|å¦| K[æ·»åŠ å·¥å…·ç»“æœåˆ°ä¸Šä¸‹æ–‡]
    K --> L[ä¸‹ä¸€è½®LLMè°ƒç”¨]
    L --> E
    
    J -->|æ˜¯| M{reflect_on_tool_use?}
    M -->|æ˜¯| N[åæ€LLMè°ƒç”¨]
    M -->|å¦| O[ç›´æ¥æ€»ç»“å·¥å…·ç»“æœ]
    
    N --> P[è¿”å›åæ€Response]
    O --> Q[è¿”å›æ€»ç»“Response]
```

---

## ğŸ¯ **å…³é”®è®¾è®¡ç‰¹æ€§**

### **1. å¤šæ¬¡LLMè°ƒç”¨çš„åˆç†æ€§**
- **ç¬¬ä¸€æ¬¡**ï¼šç”Ÿæˆåˆå§‹å“åº”æˆ–å·¥å…·è°ƒç”¨
- **ä¸­é—´è½®æ¬¡**ï¼šåŸºäºå·¥å…·ç»“æœçš„åç»­æ¨ç†ï¼ˆå·¥å…·è°ƒç”¨å¾ªç¯ï¼‰
- **æœ€åä¸€æ¬¡**ï¼šåæ€å·¥å…·ä½¿ç”¨ç»“æœï¼Œç”Ÿæˆç”¨æˆ·å‹å¥½çš„è§£é‡Š

### **2. æµå¼å¤„ç†æ”¯æŒ**
- æ‰€æœ‰LLMè°ƒç”¨éƒ½æ”¯æŒæµå¼å“åº”
- å·¥å…·æ‰§è¡Œä¹Ÿæ”¯æŒæµå¼äº‹ä»¶
- ç”¨æˆ·å¯ä»¥å®æ—¶çœ‹åˆ°å¤„ç†è¿›åº¦

### **3. å·¥å…·è°ƒç”¨å¾ªç¯**
- æ”¯æŒæœ€å¤š `max_tool_iterations` è½®å·¥å…·è°ƒç”¨
- æ¯è½®å¯ä»¥åŸºäºå‰ä¸€è½®çš„å·¥å…·ç»“æœè¿›è¡Œæ–°çš„æ¨ç†
- æ”¯æŒå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡

### **4. çµæ´»çš„è¾“å‡ºæ ¼å¼**
- æ”¯æŒçº¯æ–‡æœ¬å“åº”
- æ”¯æŒç»“æ„åŒ–JSONè¾“å‡º
- æ”¯æŒå·¥å…·æ‰§è¡Œæ€»ç»“

### **5. é”™è¯¯å¤„ç†å’Œç§»äº¤**
- æ”¯æŒä»»åŠ¡ç§»äº¤æœºåˆ¶
- å®Œå–„çš„å¼‚å¸¸å¤„ç†
- å–æ¶ˆä»¤ç‰Œæ”¯æŒ

---

## ğŸ“Š **ä¸ CodeAgent çš„å¯¹æ¯”**

| ç‰¹æ€§ | AssistantAgent | CodeAgent |
|------|----------------|-----------|
| **LLMè°ƒç”¨æ¬¡æ•°** | 1-Næ¬¡ï¼ˆå¾ªç¯+åæ€ï¼‰ | 1æ¬¡ |
| **å·¥å…·ç±»å‹** | é€šç”¨å·¥å…· | ä¸“ç”¨ä»£ç æ‰§è¡Œ |
| **æµå¼å¤„ç†** | å…¨æµç¨‹æµå¼ | å®æ—¶ä»£ç ç›‘æ§ |
| **å¤æ‚åº¦** | é«˜ï¼ˆå¤šè½®æ¨ç†ï¼‰ | ä¸­ï¼ˆå•è½®ç›‘æ§ï¼‰ |
| **é€‚ç”¨åœºæ™¯** | å¤æ‚ä»»åŠ¡åä½œ | ä»£ç æ‰§è¡Œå’Œè§£é‡Š |
| **è¾“å‡ºæ ¼å¼** | å¤šç§æ ¼å¼ | æ‰§è¡Œç»“æœç›´å‡º |

è¿™ç§è®¾è®¡ä½¿å¾— AssistantAgent èƒ½å¤Ÿå¤„ç†å¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ï¼Œè€Œ CodeAgent åˆ™ä¸“æ³¨äºé«˜æ•ˆçš„ä»£ç æ‰§è¡Œä½“éªŒã€‚